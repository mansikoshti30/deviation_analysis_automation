{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b4025c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezdxf\n",
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict, Counter\n",
    "import ezdxf\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, Point\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d75c03",
   "metadata": {},
   "source": [
    "Read dwg file and convert into dxf using ODA convertor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8770951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return code: 0\n",
      "STDOUT:\n",
      " \n",
      "STDERR:\n",
      " \n",
      "Converted DXF files: ['D:\\\\2_Analytics\\\\6_plan_vs_actual\\\\raw_data_dwg_file\\\\dxf_file\\\\ACW_NLM_Proposed_Pit_and_Dumping_area_for_FY_2024-25.dxf']\n"
     ]
    }
   ],
   "source": [
    "input_folder = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\dwg_file\"\n",
    "output_folder = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\dxf_file\"\n",
    "oda_exe = r\"C:\\Program Files\\ODA\\ODAFileConverter 26.7.0\\ODAFileConverter.exe\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "cmd = [\n",
    "    oda_exe,\n",
    "    input_folder,\n",
    "    output_folder,\n",
    "    \"ACAD2013\",  # safer than 2010\n",
    "    \"DXF\",\n",
    "    \"0\",\n",
    "    \"*.dwg\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "print(\"Return code:\", result.returncode)\n",
    "print(\"STDOUT:\\n\", result.stdout)\n",
    "print(\"STDERR:\\n\", result.stderr)\n",
    "\n",
    "dxf_files = glob.glob(os.path.join(output_folder, \"*.dxf\"))\n",
    "print(\"Converted DXF files:\", dxf_files)\n",
    "\n",
    "\n",
    "\n",
    "def ODA_convertor(input_folder, output_folder, oda_exe):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    cmd = [\n",
    "        oda_exe,\n",
    "        input_folder,\n",
    "        output_folder,\n",
    "        \"ACAD2013\",  # safer than 2010\n",
    "        \"DXF\",\n",
    "        \"0\",\n",
    "        \"*.dwg\"\n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    dxf_files = glob.glob(os.path.join(output_folder, \"*.dxf\"))\n",
    "\n",
    "    print(dxf_files)\n",
    "\n",
    "    return dxf_files\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce10c0d",
   "metadata": {},
   "source": [
    "Read DXF file and split data into multiple layer and fetch section lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f724a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Selected layer: 'SECTION LINE NAUKARI LST'\n",
      "   - Text count: 36\n",
      "   - Entity total: 55\n",
      "   - LINE: 5\n",
      "   - LWPOLYLINE: 14\n",
      "   - MTEXT: 36\n",
      " Saved as: D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_by_layer_3\\section_lines.dxf\n"
     ]
    }
   ],
   "source": [
    "# === INPUT \n",
    "input_dxf = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\dxf_file\\ACW_NLM_Proposed_Pit_and_Dumping_area_for_FY_2024-25.dxf\"\n",
    "output_folder = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_by_layer_3\"\n",
    "\n",
    "def get_layers_from_dxf(input_dxf, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    out_file = os.path.join(output_folder, \"section_lines.dxf\")\n",
    "\n",
    "    # === RULES ===\n",
    "    # Only these types are allowed in the target \"section lines\" layer:\n",
    "    ALLOWED_TYPES = {\"LINE\", \"LWPOLYLINE\", \"TEXT\", \"MTEXT\"}\n",
    "    # Explicitly disallow common polygonal/fill types:\n",
    "    DISALLOWED_TYPES = {\"HATCH\", \"POLYLINE\"}  # add more if needed (e.g., \"SPLINE\", \"CIRCLE\", ...)\n",
    "\n",
    "    def is_lwpolyline_closed(lp) -> bool:\n",
    "        \"\"\"Return True if an LWPOLYLINE is closed.\"\"\"\n",
    "        # ezdxf LWPOLYLINE exposes .closed property in recent versions\n",
    "        closed_attr = getattr(lp, \"closed\", None)\n",
    "        if isinstance(closed_attr, bool):\n",
    "            return closed_attr\n",
    "        # Fallback: check DXF flags bit 1\n",
    "        try:\n",
    "            flags = int(lp.dxf.flags)\n",
    "            return bool(flags & 1)\n",
    "        except Exception:\n",
    "            # If we can't determine, be conservative and treat as closed\n",
    "            return True\n",
    "\n",
    "    def layer_matches_section_criteria(entities):\n",
    "        \"\"\"Check that a layer contains ONLY allowed types, with at least one text and one line-ish entity,\n",
    "        and that NO LWPOLYLINE is closed (i.e., no polygons).\"\"\"\n",
    "        if not entities:\n",
    "            return False\n",
    "\n",
    "        type_counts = Counter(e.dxftype() for e in entities)\n",
    "\n",
    "        # Hard disallow first\n",
    "        if any(t in DISALLOWED_TYPES for t in type_counts):\n",
    "            return False\n",
    "\n",
    "        # Must be subset of allowed types\n",
    "        if not set(type_counts).issubset(ALLOWED_TYPES):\n",
    "            return False\n",
    "\n",
    "        # Must have some text (section letters)\n",
    "        text_count = type_counts.get(\"TEXT\", 0) + type_counts.get(\"MTEXT\", 0)\n",
    "        if text_count == 0:\n",
    "            return False\n",
    "\n",
    "        # Must have some lines (LINE or LWPOLYLINE)\n",
    "        lineish_count = type_counts.get(\"LINE\", 0) + type_counts.get(\"LWPOLYLINE\", 0)\n",
    "        if lineish_count == 0:\n",
    "            return False\n",
    "\n",
    "        # Ensure no LWPOLYLINE is closed (to avoid polygons)\n",
    "        for e in entities:\n",
    "            if e.dxftype() == \"LWPOLYLINE\" and is_lwpolyline_closed(e):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def save_entities_as_dxf(entities, filename):\n",
    "        \"\"\"Save given entities to a fresh DXF.\"\"\"\n",
    "        new_doc = ezdxf.new(setup=True)\n",
    "        new_msp = new_doc.modelspace()\n",
    "        for e in entities:\n",
    "            try:\n",
    "                new_msp.add_foreign_entity(e)\n",
    "            except Exception as ex:\n",
    "                print(f\"  Skipped {e.dxftype()}: {ex}\")\n",
    "        new_doc.saveas(filename)\n",
    "\n",
    "    # === LOAD & EVALUATE ===\n",
    "    doc = ezdxf.readfile(input_dxf)\n",
    "    msp = doc.modelspace()\n",
    "\n",
    "    # Group entities by layer\n",
    "    layer_entities = defaultdict(list)\n",
    "    for ent in msp:\n",
    "        layer_entities[ent.dxf.layer].append(ent)\n",
    "\n",
    "    # Find candidate layers that satisfy criteria\n",
    "    candidates = []\n",
    "    for layer, ents in layer_entities.items():\n",
    "        if layer_matches_section_criteria(ents):\n",
    "            # Score by text count (prefer layer with most section letters)\n",
    "            tcount = sum(1 for e in ents if e.dxftype() in (\"TEXT\", \"MTEXT\"))\n",
    "            total = len(ents)\n",
    "            candidates.append((layer, tcount, total, ents))\n",
    "\n",
    "    if not candidates:\n",
    "        print(\" No layer matched the 'section lines + letters' criteria.\")\n",
    "    else:\n",
    "        # Pick the best candidate: highest text count, then most entities as tiebreaker\n",
    "        candidates.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "        best_layer, best_texts, best_total, best_entities = candidates[0]\n",
    "\n",
    "        # Save as section_lines.dxf (overwrite intentionally)\n",
    "        save_entities_as_dxf(best_entities, out_file)\n",
    "\n",
    "        # Console report\n",
    "        print(f\" Selected layer: '{best_layer}'\")\n",
    "        print(f\"   - Text count: {best_texts}\")\n",
    "        print(f\"   - Entity total: {best_total}\")\n",
    "        # Type breakdown for visibility\n",
    "        type_counts = Counter(e.dxftype() for e in best_entities)\n",
    "        for t, c in sorted(type_counts.items()):\n",
    "            print(f\"   - {t}: {c}\")\n",
    "        print(f\" Saved as: {out_file}\")\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491d7cd2",
   "metadata": {},
   "source": [
    "Remove duplicates from section line dxf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31a9146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique line segments: 18\n",
      "Unique TEXT by geometry: 0\n",
      "Unique MTEXT by geometry: 36\n",
      "Cleaned DXF saved to: D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_by_layer_3\\section_lines_clean.dxf\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Config ----------------\n",
    "# Paths\n",
    "section_lines_dxf = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_by_layer_3\\section_lines.dxf\"\n",
    "output_folder = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_by_layer_3\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Tolerance via rounding precision (same approach you used)\n",
    "PREC = 6  # decimals\n",
    "\n",
    "# -------------- Helpers -----------------\n",
    "def qr(val, p=PREC):\n",
    "    return round(float(val), p)\n",
    "\n",
    "def qpt3(v, p=PREC):\n",
    "    # (x, y, z) with rounding\n",
    "    if hasattr(v, \"x\"):\n",
    "        return (qr(v.x, p), qr(v.y, p), qr(getattr(v, \"z\", 0.0), p))\n",
    "    # assume tuple-like\n",
    "    if len(v) == 2:\n",
    "        return (qr(v[0], p), qr(v[1], p), 0.0)\n",
    "    return (qr(v[0], p), qr(v[1], p), qr(v[2], p))\n",
    "\n",
    "# ---------- Read source DXF ----------\n",
    "doc_in = ezdxf.readfile(section_lines_dxf)\n",
    "msp_in = doc_in.modelspace()\n",
    "\n",
    "# ---------- Deduplicate GEOMETRY ----------\n",
    "line_set = set()            # stores normalized segment tuples: ((x1,y1,z1),(x2,y2,z2))\n",
    "text_geo_to_entity = {}     # key -> exemplar TEXT entity (keep first)\n",
    "mtext_geo_to_entity = {}    # key -> exemplar MTEXT entity (keep first)\n",
    "\n",
    "# ----- LINE entities -----\n",
    "for line in msp_in.query(\"LINE\"):\n",
    "    start = qpt3(line.dxf.start)\n",
    "    end = qpt3(line.dxf.end)\n",
    "    key = tuple(sorted([start, end]))\n",
    "    line_set.add(key)\n",
    "\n",
    "# ----- LWPOLYLINE entities (as segments) -----\n",
    "for pl in msp_in.query(\"LWPOLYLINE\"):\n",
    "    pts = list(pl.get_points(\"xy\"))\n",
    "    if len(pts) >= 2:\n",
    "        for i in range(len(pts) - 1):\n",
    "            a = (qr(pts[i][0]), qr(pts[i][1]), 0.0)\n",
    "            b = (qr(pts[i+1][0]), qr(pts[i+1][1]), 0.0)\n",
    "            key = tuple(sorted([a, b]))\n",
    "            line_set.add(key)\n",
    "        if pl.closed and len(pts) > 2:\n",
    "            a = (qr(pts[-1][0]), qr(pts[-1][1]), 0.0)\n",
    "            b = (qr(pts[0][0]), qr(pts[0][1]), 0.0)\n",
    "            key = tuple(sorted([a, b]))\n",
    "            line_set.add(key)\n",
    "\n",
    "# ----- TEXT entities (geometry-only) -----\n",
    "for tx in msp_in.query(\"TEXT\"):\n",
    "    ins = qpt3(tx.dxf.insert)\n",
    "    h = qr(tx.dxf.height) if tx.dxf.hasattr(\"height\") else 0.0\n",
    "    rot = qr(tx.dxf.rotation) if tx.dxf.hasattr(\"rotation\") else 0.0\n",
    "    key = (\"TEXT\", ins, h, rot)\n",
    "    # keep first seen by geometry\n",
    "    if key not in text_geo_to_entity:\n",
    "        text_geo_to_entity[key] = tx\n",
    "\n",
    "# ----- MTEXT entities (geometry-only) -----\n",
    "for mt in msp_in.query(\"MTEXT\"):\n",
    "    ins = qpt3(mt.dxf.insert)\n",
    "    h = qr(mt.dxf.char_height) if mt.dxf.hasattr(\"char_height\") else 0.0\n",
    "    w = qr(mt.dxf.width) if mt.dxf.hasattr(\"width\") else 0.0\n",
    "    rot = qr(mt.dxf.rotation) if mt.dxf.hasattr(\"rotation\") else 0.0\n",
    "    key = (\"MTEXT\", ins, h, w, rot)\n",
    "    if key not in mtext_geo_to_entity:\n",
    "        mtext_geo_to_entity[key] = mt\n",
    "\n",
    "print(f\"Unique line segments: {len(line_set)}\")\n",
    "print(f\"Unique TEXT by geometry: {len(text_geo_to_entity)}\")\n",
    "print(f\"Unique MTEXT by geometry: {len(mtext_geo_to_entity)}\")\n",
    "\n",
    "# ---------- Write new DXF with uniques ----------\n",
    "doc_out = ezdxf.new(setup=True)\n",
    "msp_out = doc_out.modelspace()\n",
    "\n",
    "# Optionally copy over layers first so created entities preserve original layers if you assign them.\n",
    "# (ezdxf auto-creates layers on assignment, so this is optional.)\n",
    "\n",
    "# Lines\n",
    "for start, end in line_set:\n",
    "    # msp.add_line accepts (x,y[,z]) tuples directly\n",
    "    e = msp_out.add_line(start, end)\n",
    "\n",
    "# TEXT – recreate using exemplar's geometry; content is from the first encountered entity\n",
    "for key, tx in text_geo_to_entity.items():\n",
    "    _, ins, h, rot = key\n",
    "    # Create text; preserve layer for familiarity (not part of geometry, but safe to keep)\n",
    "    new_tx = msp_out.add_text(tx.dxf.text or \"\", dxfattribs={\n",
    "        \"height\": h,\n",
    "        \"rotation\": rot,\n",
    "        \"layer\": tx.dxf.layer if tx.dxf.hasattr(\"layer\") else \"0\",\n",
    "    })\n",
    "    new_tx.set_pos(ins)  # sets insert (and aligns as baseline-left by default)\n",
    "\n",
    "# MTEXT – recreate using exemplar's geometry; content from first encountered entity\n",
    "for key, mt in mtext_geo_to_entity.items():\n",
    "    _, ins, h, w, rot = key\n",
    "    new_mt = msp_out.add_mtext(mt.text or \"\", dxfattribs={\n",
    "        \"char_height\": h,\n",
    "        \"width\": w,\n",
    "        \"rotation\": rot,\n",
    "        \"layer\": mt.dxf.layer if mt.dxf.hasattr(\"layer\") else \"0\",\n",
    "    })\n",
    "    new_mt.set_location(ins)\n",
    "\n",
    "out_path = os.path.join(output_folder, \"section_lines_clean.dxf\")\n",
    "doc_out.saveas(out_path)\n",
    "print(\"Cleaned DXF saved to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f03edc4",
   "metadata": {},
   "source": [
    "Assign the text to each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15583eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete: 18 lines, 36 texts\n",
      "Deduplicated lines: 18\n",
      " Deduplicated texts: 36\n",
      " Final line shapefile with start/end texts saved: D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_by_layer_3\\processed\\LINES_with_start_end_text.shp\n"
     ]
    }
   ],
   "source": [
    "# ---------- Input & Output ----------\n",
    "input_dxf = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_by_layer_3\\section_lines_clean.dxf\"\n",
    "work_dir = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_by_layer_3\\processed\"\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "\n",
    "lines_dxf = os.path.join(work_dir, \"LINES.dxf\")\n",
    "texts_dxf = os.path.join(work_dir, \"TEXTS.dxf\")\n",
    "output_shp = os.path.join(work_dir, \"LINES_with_start_end_text.shp\")\n",
    "\n",
    "# ---------- Step 1: Split DXF ----------\n",
    "doc = ezdxf.readfile(input_dxf)\n",
    "msp = doc.modelspace()\n",
    "\n",
    "line_entities, text_entities = [], []\n",
    "for e in msp:\n",
    "    etype = e.dxftype()\n",
    "    if etype in [\"LINE\", \"LWPOLYLINE\"]:\n",
    "        line_entities.append(e)\n",
    "    elif etype in [\"TEXT\", \"MTEXT\"]:\n",
    "        text_entities.append(e)\n",
    "\n",
    "# Save lines\n",
    "if line_entities:\n",
    "    doc_lines = ezdxf.new(setup=True)\n",
    "    msp_lines = doc_lines.modelspace()\n",
    "    for e in line_entities:\n",
    "        try:\n",
    "            msp_lines.add_foreign_entity(e)\n",
    "        except Exception as ex:\n",
    "            print(f\" Skipped line entity: {ex}\")\n",
    "    doc_lines.saveas(lines_dxf)\n",
    "\n",
    "# Save texts\n",
    "if text_entities:\n",
    "    doc_texts = ezdxf.new(setup=True)\n",
    "    msp_texts = doc_texts.modelspace()\n",
    "    for e in text_entities:\n",
    "        try:\n",
    "            msp_texts.add_foreign_entity(e)\n",
    "        except Exception as ex:\n",
    "            print(f\" Skipped text entity: {ex}\")\n",
    "    doc_texts.saveas(texts_dxf)\n",
    "\n",
    "print(f\"Split complete: {len(line_entities)} lines, {len(text_entities)} texts\")\n",
    "\n",
    "# ---------- Step 2: Convert Lines to GeoDataFrame ----------\n",
    "doc_lines = ezdxf.readfile(lines_dxf)\n",
    "msp_lines = doc_lines.modelspace()\n",
    "\n",
    "lines = []\n",
    "for line in msp_lines.query(\"LINE\"):\n",
    "    start = (line.dxf.start.x, line.dxf.start.y)\n",
    "    end = (line.dxf.end.x, line.dxf.end.y)\n",
    "    lines.append({\"geometry\": LineString([start, end]), \"start\": start, \"end\": end})\n",
    "\n",
    "for pline in msp_lines.query(\"LWPOLYLINE\"):\n",
    "    pts = list(pline.get_points(\"xy\"))\n",
    "    if len(pts) > 1:\n",
    "        for i in range(len(pts) - 1):\n",
    "            start, end = pts[i], pts[i+1]\n",
    "            lines.append({\"geometry\": LineString([start, end]), \"start\": start, \"end\": end})\n",
    "        if pline.closed:\n",
    "            start, end = pts[-1], pts[0]\n",
    "            lines.append({\"geometry\": LineString([start, end]), \"start\": start, \"end\": end})\n",
    "\n",
    "gdf_lines = gpd.GeoDataFrame(lines, crs=\"EPSG:32644\")  \n",
    "gdf_lines = gdf_lines.drop_duplicates(subset=[\"geometry\"])\n",
    "print(f\"Deduplicated lines: {len(gdf_lines)}\")\n",
    "\n",
    "# ---------- Step 3: Convert Texts to GeoDataFrame ----------\n",
    "doc_texts = ezdxf.readfile(texts_dxf)\n",
    "msp_texts = doc_texts.modelspace()\n",
    "\n",
    "texts = []\n",
    "for t in msp_texts.query(\"TEXT MTEXT\"):\n",
    "    content = t.dxf.text.strip()\n",
    "    insert = (t.dxf.insert.x, t.dxf.insert.y)\n",
    "    texts.append({\"geometry\": Point(insert), \"text\": content})\n",
    "\n",
    "gdf_texts = gpd.GeoDataFrame(texts, crs=gdf_lines.crs)\n",
    "gdf_texts = gdf_texts.drop_duplicates(subset=[\"geometry\", \"text\"])\n",
    "print(f\" Deduplicated texts: {len(gdf_texts)}\")\n",
    "\n",
    "# ---------- Step 4: Nearest text for start & end ----------\n",
    "tree = cKDTree(gdf_texts.geometry.apply(lambda p: (p.x, p.y)).to_list())\n",
    "\n",
    "def nearest_text(point):\n",
    "    dist, idx = tree.query([point.x, point.y], k=1)\n",
    "    return gdf_texts.iloc[idx][\"text\"]\n",
    "\n",
    "start_labels, end_labels = [], []\n",
    "for _, row in gdf_lines.iterrows():\n",
    "    start_point = Point(row[\"start\"])\n",
    "    end_point = Point(row[\"end\"])\n",
    "    start_labels.append(nearest_text(start_point))\n",
    "    end_labels.append(nearest_text(end_point))\n",
    "\n",
    "gdf_lines[\"start_text\"] = start_labels\n",
    "gdf_lines[\"end_text\"] = end_labels\n",
    "\n",
    "# ---------- Step 5: Save Shapefile ----------\n",
    "gdf_lines.to_file(output_shp)\n",
    "print(f\" Final line shapefile with start/end texts saved: {output_shp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4faf33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408b649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c403d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607d3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e298846f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plan_actual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
