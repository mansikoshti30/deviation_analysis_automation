{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb0f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezdxf\n",
    "import subprocess\n",
    "import ezdxf\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d989f",
   "metadata": {},
   "source": [
    "1. Read and convert DWG file to DXF file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6468193e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return code: 0\n",
      "STDOUT:\n",
      " \n",
      "STDERR:\n",
      " \n",
      "Converted DXF files: ['D:\\\\2_Analytics\\\\6_plan_vs_actual\\\\raw_data_dwg_file\\\\dxf_file\\\\ACW_NLM_Proposed_Pit_and_Dumping_area_for_FY_2024-25.dxf']\n"
     ]
    }
   ],
   "source": [
    "input_folder = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\dwg_file\"\n",
    "output_folder = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\dxf_file\"\n",
    "oda_exe = r\"C:\\Program Files\\ODA\\ODAFileConverter 26.7.0\\ODAFileConverter.exe\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "cmd = [\n",
    "    oda_exe,\n",
    "    input_folder,\n",
    "    output_folder,\n",
    "    \"ACAD2013\",  # safer than 2010\n",
    "    \"DXF\",\n",
    "    \"0\",\n",
    "    \"*.dwg\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "print(\"Return code:\", result.returncode)\n",
    "print(\"STDOUT:\\n\", result.stdout)\n",
    "print(\"STDERR:\\n\", result.stderr)\n",
    "\n",
    "dxf_files = glob.glob(os.path.join(output_folder, \"*.dxf\"))\n",
    "print(\"Converted DXF files:\", dxf_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95021a12",
   "metadata": {},
   "source": [
    "2. read dxf file and split all possible features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ce80a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DXF files saved in: D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_features_new\n"
     ]
    }
   ],
   "source": [
    "# Input DXF file\n",
    "input_dxf = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\dxf_file\\ACW_NLM_Proposed_Pit_and_Dumping_area_for_FY_2024-25.dxf\"\n",
    "\n",
    "# Output folder\n",
    "output_folder = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_features_new\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read DXF\n",
    "doc = ezdxf.readfile(input_dxf)\n",
    "msp = doc.modelspace()\n",
    "\n",
    "# Buckets for separated entities\n",
    "lines = []\n",
    "polygons = []\n",
    "points = []\n",
    "circles = []\n",
    "arcs = []\n",
    "texts = []\n",
    "hatches = []\n",
    "\n",
    "# Iterate over entities\n",
    "for entity in msp:\n",
    "    etype = entity.dxftype()\n",
    "\n",
    "    if etype == \"LINE\":\n",
    "        lines.append(entity)\n",
    "\n",
    "    elif etype == \"POINT\":\n",
    "        points.append(entity)\n",
    "\n",
    "    elif etype in [\"LWPOLYLINE\", \"POLYLINE\"]:\n",
    "        if entity.closed:   # closed polyline = polygon\n",
    "            polygons.append(entity)\n",
    "        else:\n",
    "            lines.append(entity)\n",
    "\n",
    "    elif etype == \"CIRCLE\":\n",
    "        polygons.append(entity)  # treat circle as polygon (closed shape)\n",
    "\n",
    "    elif etype == \"ARC\":\n",
    "        arcs.append(entity)\n",
    "\n",
    "    elif etype in [\"TEXT\", \"MTEXT\"]:\n",
    "        texts.append(entity)\n",
    "\n",
    "    elif etype == \"HATCH\":\n",
    "        polygons.append(entity)  # hatch = polygon-like fill\n",
    "\n",
    "# Function to save entities into new DXF\n",
    "def save_entities(entities, filename):\n",
    "    if not entities:\n",
    "        return\n",
    "    new_doc = ezdxf.new(setup=True)\n",
    "    new_msp = new_doc.modelspace()\n",
    "    for e in entities:\n",
    "        try:\n",
    "            new_msp.add_foreign_entity(e)\n",
    "        except Exception as ex:\n",
    "            print(f\"Skipped {e.dxftype()}: {ex}\")\n",
    "    new_doc.saveas(filename)\n",
    "\n",
    "# Save to separate DXF files\n",
    "save_entities(lines, os.path.join(output_folder, \"LINES.dxf\"))\n",
    "save_entities(polygons, os.path.join(output_folder, \"POLYGONS.dxf\"))\n",
    "save_entities(points, os.path.join(output_folder, \"POINTS.dxf\"))\n",
    "save_entities(circles, os.path.join(output_folder, \"CIRCLES.dxf\"))\n",
    "save_entities(arcs, os.path.join(output_folder, \"ARCS.dxf\"))\n",
    "save_entities(texts, os.path.join(output_folder, \"TEXTS.dxf\"))\n",
    "save_entities(hatches, os.path.join(output_folder, \"HATCHES.dxf\"))\n",
    "\n",
    "print(\" DXF files saved in:\", output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2fb5b9",
   "metadata": {},
   "source": [
    "remove duplicates fron line dxf file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d0fd510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unique lines found: 18\n",
      " Cleaned line DXF saved in: D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_features_new\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "lines_dxf = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_features_new\\LINES.dxf\"\n",
    "output_folder = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_features_new\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ---------- Deduplicate Lines ----------\n",
    "doc_lines = ezdxf.readfile(lines_dxf)\n",
    "msp_lines = doc_lines.modelspace()\n",
    "\n",
    "line_set = set()\n",
    "\n",
    "# LINE entities\n",
    "for line in msp_lines.query(\"LINE\"):\n",
    "    start = (round(line.dxf.start.x, 6), round(line.dxf.start.y, 6), round(line.dxf.start.z, 6))\n",
    "    end = (round(line.dxf.end.x, 6), round(line.dxf.end.y, 6), round(line.dxf.end.z, 6))\n",
    "    # normalize order\n",
    "    key = tuple(sorted([start, end]))\n",
    "    line_set.add(key)\n",
    "\n",
    "# LWPOLYLINE entities\n",
    "for pline in msp_lines.query(\"LWPOLYLINE\"):\n",
    "    points = list(pline.get_points(\"xy\"))\n",
    "    # break into segments\n",
    "    for i in range(len(points) - 1):\n",
    "        start = (round(points[i][0], 6), round(points[i][1], 6))\n",
    "        end = (round(points[i+1][0], 6), round(points[i+1][1], 6))\n",
    "        key = tuple(sorted([start, end]))\n",
    "        line_set.add(key)\n",
    "    if pline.closed and len(points) > 2:\n",
    "        start = (round(points[-1][0], 6), round(points[-1][1], 6))\n",
    "        end = (round(points[0][0], 6), round(points[0][1], 6))\n",
    "        key = tuple(sorted([start, end]))\n",
    "        line_set.add(key)\n",
    "\n",
    "print(f\" Unique lines found: {len(line_set)}\")\n",
    "\n",
    "# Save deduplicated lines\n",
    "doc_new_lines = ezdxf.new(setup=True)\n",
    "msp_new_lines = doc_new_lines.modelspace()\n",
    "for start, end in line_set:\n",
    "    msp_new_lines.add_line(start, end)\n",
    "doc_new_lines.saveas(os.path.join(output_folder, \"LINES_clean.dxf\"))\n",
    "\n",
    "\n",
    "print(\" Cleaned line DXF saved in:\", output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c299d6b",
   "metadata": {},
   "source": [
    "Remove duplicates from text dxf file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8907da",
   "metadata": {},
   "source": [
    "get the text near to end points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e20609b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line shapefile with labels saved at: D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_features_new\\LINES_with_attributes.shp\n"
     ]
    }
   ],
   "source": [
    "import ezdxf\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, Point\n",
    "from scipy.spatial import cKDTree\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Input DXF paths ----------\n",
    "lines_dxf = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_features_new\\LINES_clean.dxf\"\n",
    "texts_dxf = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_features_new\\TEXTS_cleaned.dxf\"\n",
    "\n",
    "# ---------- Step 1: Extract Lines ----------\n",
    "doc_lines = ezdxf.readfile(lines_dxf)\n",
    "msp_lines = doc_lines.modelspace()\n",
    "\n",
    "lines = []\n",
    "for line in msp_lines.query(\"LINE\"):\n",
    "    start = (line.dxf.start.x, line.dxf.start.y)\n",
    "    end = (line.dxf.end.x, line.dxf.end.y)\n",
    "    lines.append({\"geometry\": LineString([start, end]), \"start\": start, \"end\": end})\n",
    "\n",
    "# Also include polyline segments\n",
    "for pline in msp_lines.query(\"LWPOLYLINE\"):\n",
    "    points = list(pline.get_points(\"xy\"))\n",
    "    for i in range(len(points) - 1):\n",
    "        start, end = points[i], points[i + 1]\n",
    "        lines.append({\"geometry\": LineString([start, end]), \"start\": start, \"end\": end})\n",
    "    if pline.closed and len(points) > 2:\n",
    "        start, end = points[-1], points[0]\n",
    "        lines.append({\"geometry\": LineString([start, end]), \"start\": start, \"end\": end})\n",
    "\n",
    "gdf_lines = gpd.GeoDataFrame(lines, crs=\"EPSG:32644\")  # CRS\n",
    "\n",
    "# ---------- Step 2: Extract Texts ----------\n",
    "doc_texts = ezdxf.readfile(texts_dxf)\n",
    "msp_texts = doc_texts.modelspace()\n",
    "\n",
    "texts = []\n",
    "for t in msp_texts.query(\"TEXT MTEXT\"):\n",
    "    content = t.dxf.text.strip()\n",
    "    insert = (t.dxf.insert.x, t.dxf.insert.y)\n",
    "    texts.append({\"geometry\": Point(insert), \"text\": content})\n",
    "\n",
    "gdf_texts = gpd.GeoDataFrame(texts, crs=gdf_lines.crs)\n",
    "\n",
    "# ---------- Step 3: Build KDTree for fast nearest search ----------\n",
    "tree = cKDTree(gdf_texts.geometry.apply(lambda p: (p.x, p.y)).to_list())\n",
    "\n",
    "def nearest_text(point):\n",
    "    dist, idx = tree.query([point.x, point.y], k=1)\n",
    "    return gdf_texts.iloc[idx][\"text\"]\n",
    "\n",
    "# ---------- Step 4: Assign nearest texts to each line endpoint ----------\n",
    "start_texts = []\n",
    "end_texts = []\n",
    "\n",
    "for idx, row in gdf_lines.iterrows():\n",
    "    start_point = Point(row[\"start\"])\n",
    "    end_point = Point(row[\"end\"])\n",
    "    start_texts.append(nearest_text(start_point))\n",
    "    end_texts.append(nearest_text(end_point))\n",
    "\n",
    "gdf_lines[\"start_text\"] = start_texts\n",
    "gdf_lines[\"end_text\"] = end_texts\n",
    "\n",
    "# ---------- Step 5: Save final shapefile ----------\n",
    "output_shp = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_features_new\\LINES_with_attributes.shp\"\n",
    "gdf_lines.to_file(output_shp)\n",
    "\n",
    "print(f\"Line shapefile with labels saved at: {output_shp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e24f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete: 19 lines, 36 texts\n",
      "Deduplicated lines: 18\n",
      " Deduplicated texts: 36\n",
      " Final line shapefile with start/end texts saved: D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_by_layer\\processed\\LINES_with_start_end_text.shp\n"
     ]
    }
   ],
   "source": [
    "import ezdxf\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, Point\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# ---------- Input & Output ----------\n",
    "input_dxf = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_by_layer\\SECTION_LINE_NAUKARI_LST.dxf\"\n",
    "work_dir = r\"D:\\2_Analytics\\6_plan_vs_actual\\raw_data_dwg_file\\split_by_layer\\processed\"\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "\n",
    "lines_dxf = os.path.join(work_dir, \"LINES.dxf\")\n",
    "texts_dxf = os.path.join(work_dir, \"TEXTS.dxf\")\n",
    "output_shp = os.path.join(work_dir, \"LINES_with_start_end_text.shp\")\n",
    "\n",
    "# ---------- Step 1: Split DXF ----------\n",
    "doc = ezdxf.readfile(input_dxf)\n",
    "msp = doc.modelspace()\n",
    "\n",
    "line_entities, text_entities = [], []\n",
    "for e in msp:\n",
    "    etype = e.dxftype()\n",
    "    if etype in [\"LINE\", \"LWPOLYLINE\"]:\n",
    "        line_entities.append(e)\n",
    "    elif etype in [\"TEXT\", \"MTEXT\"]:\n",
    "        text_entities.append(e)\n",
    "\n",
    "# Save lines\n",
    "if line_entities:\n",
    "    doc_lines = ezdxf.new(setup=True)\n",
    "    msp_lines = doc_lines.modelspace()\n",
    "    for e in line_entities:\n",
    "        try:\n",
    "            msp_lines.add_foreign_entity(e)\n",
    "        except Exception as ex:\n",
    "            print(f\" Skipped line entity: {ex}\")\n",
    "    doc_lines.saveas(lines_dxf)\n",
    "\n",
    "# Save texts\n",
    "if text_entities:\n",
    "    doc_texts = ezdxf.new(setup=True)\n",
    "    msp_texts = doc_texts.modelspace()\n",
    "    for e in text_entities:\n",
    "        try:\n",
    "            msp_texts.add_foreign_entity(e)\n",
    "        except Exception as ex:\n",
    "            print(f\" Skipped text entity: {ex}\")\n",
    "    doc_texts.saveas(texts_dxf)\n",
    "\n",
    "print(f\"Split complete: {len(line_entities)} lines, {len(text_entities)} texts\")\n",
    "\n",
    "# ---------- Step 2: Convert Lines to GeoDataFrame ----------\n",
    "doc_lines = ezdxf.readfile(lines_dxf)\n",
    "msp_lines = doc_lines.modelspace()\n",
    "\n",
    "lines = []\n",
    "for line in msp_lines.query(\"LINE\"):\n",
    "    start = (line.dxf.start.x, line.dxf.start.y)\n",
    "    end = (line.dxf.end.x, line.dxf.end.y)\n",
    "    lines.append({\"geometry\": LineString([start, end]), \"start\": start, \"end\": end})\n",
    "\n",
    "for pline in msp_lines.query(\"LWPOLYLINE\"):\n",
    "    pts = list(pline.get_points(\"xy\"))\n",
    "    if len(pts) > 1:\n",
    "        for i in range(len(pts) - 1):\n",
    "            start, end = pts[i], pts[i+1]\n",
    "            lines.append({\"geometry\": LineString([start, end]), \"start\": start, \"end\": end})\n",
    "        if pline.closed:\n",
    "            start, end = pts[-1], pts[0]\n",
    "            lines.append({\"geometry\": LineString([start, end]), \"start\": start, \"end\": end})\n",
    "\n",
    "gdf_lines = gpd.GeoDataFrame(lines, crs=\"EPSG:32644\")  \n",
    "gdf_lines = gdf_lines.drop_duplicates(subset=[\"geometry\"])\n",
    "print(f\"Deduplicated lines: {len(gdf_lines)}\")\n",
    "\n",
    "# ---------- Step 3: Convert Texts to GeoDataFrame ----------\n",
    "doc_texts = ezdxf.readfile(texts_dxf)\n",
    "msp_texts = doc_texts.modelspace()\n",
    "\n",
    "texts = []\n",
    "for t in msp_texts.query(\"TEXT MTEXT\"):\n",
    "    content = t.dxf.text.strip()\n",
    "    insert = (t.dxf.insert.x, t.dxf.insert.y)\n",
    "    texts.append({\"geometry\": Point(insert), \"text\": content})\n",
    "\n",
    "gdf_texts = gpd.GeoDataFrame(texts, crs=gdf_lines.crs)\n",
    "gdf_texts = gdf_texts.drop_duplicates(subset=[\"geometry\", \"text\"])\n",
    "print(f\" Deduplicated texts: {len(gdf_texts)}\")\n",
    "\n",
    "# ---------- Step 4: Nearest text for start & end ----------\n",
    "tree = cKDTree(gdf_texts.geometry.apply(lambda p: (p.x, p.y)).to_list())\n",
    "\n",
    "def nearest_text(point):\n",
    "    dist, idx = tree.query([point.x, point.y], k=1)\n",
    "    return gdf_texts.iloc[idx][\"text\"]\n",
    "\n",
    "start_labels, end_labels = [], []\n",
    "for _, row in gdf_lines.iterrows():\n",
    "    start_point = Point(row[\"start\"])\n",
    "    end_point = Point(row[\"end\"])\n",
    "    start_labels.append(nearest_text(start_point))\n",
    "    end_labels.append(nearest_text(end_point))\n",
    "\n",
    "gdf_lines[\"start_text\"] = start_labels\n",
    "gdf_lines[\"end_text\"] = end_labels\n",
    "\n",
    "# ---------- Step 5: Save Shapefile ----------\n",
    "gdf_lines.to_file(output_shp)\n",
    "print(f\" Final line shapefile with start/end texts saved: {output_shp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747461d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plan_actual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
